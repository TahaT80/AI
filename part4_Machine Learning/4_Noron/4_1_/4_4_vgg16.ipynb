{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c698c3df",
      "metadata": {
        "id": "c698c3df"
      },
      "outputs": [],
      "source": [
        "from keras.applications import VGG16\n",
        "from keras.applications import imagenet_utils\n",
        "# from keras.preprocessing.image import img_to_array\n",
        "# from keras.preprocessing.image import load_img\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "377276d9",
      "metadata": {
        "id": "377276d9"
      },
      "outputs": [],
      "source": [
        "model = VGG16(include_top=False,input_shape=(48,144,3),pooling=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3d2b738f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "3d2b738f",
        "outputId": "657d8333-99fc-4511-c77b-42857a10c1f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 144, 3)]      0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 144, 64)       1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 144, 64)       36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 72, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 72, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 72, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 36, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 36, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 36, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 36, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 18, 256)        0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 18, 512)        1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 18, 512)        2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 18, 512)        2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b72fa7cb",
      "metadata": {
        "id": "b72fa7cb"
      },
      "outputs": [],
      "source": [
        "for l in model.layers:\n",
        "    l.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8a5b61",
      "metadata": {
        "id": "3b8a5b61"
      },
      "outputs": [],
      "source": [
        "a = Flatten()(model.output)\n",
        "a = Dense(512,activation='relu')(a)\n",
        "a = Dense(254,activation='relu')(a)\n",
        "a = Dense(64,activation='relu')(a)\n",
        "\n",
        "out1 = Dense(32, activation=\"softmax\", name=\"out1\")(a)\n",
        "out2 = Dense(32, activation=\"softmax\", name=\"out2\")(a)\n",
        "out3 = Dense(32, activation=\"softmax\", name=\"out3\")(a)\n",
        "out4 = Dense(32, activation=\"softmax\", name=\"out4\")(a)\n",
        "\n",
        "\n",
        "model2 = Model(model.input,outputs=[out1, out2, out3, out4])\n",
        "model2.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        \"out1\": \"categorical_crossentropy\",\n",
        "        \"out2\": \"categorical_crossentropy\",\n",
        "        \"out3\": \"categorical_crossentropy\",\n",
        "        \"out4\": \"categorical_crossentropy\"\n",
        "    },\n",
        "    metrics={\n",
        "        \"out1\": [\"accuracy\"],\n",
        "        \"out2\": [\"accuracy\"],\n",
        "        \"out3\": [\"accuracy\"],\n",
        "        \"out4\": [\"accuracy\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "08dfffb2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "08dfffb2",
        "outputId": "13907e86-e172-4ecc-9235-7c32eb0b620f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 48, 144, 3)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 48, 144, 64)  1792        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 48, 144, 64)  36928       ['block1_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 24, 72, 64)   0           ['block1_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 24, 72, 128)  73856       ['block1_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 24, 72, 128)  147584      ['block2_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 12, 36, 128)  0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 12, 36, 256)  295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 12, 36, 256)  590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 12, 36, 256)  590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 6, 18, 256)   0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 6, 18, 512)   1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 6, 18, 512)   2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 6, 18, 512)   2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 3, 9, 512)    0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 3, 9, 512)    2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 3, 9, 512)    2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 3, 9, 512)    2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 1, 4, 512)    0           ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['block5_pool[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          262272      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64)           8256        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " char1 (Dense)                  (None, 32)           2080        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " char2 (Dense)                  (None, 32)           2080        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " char3 (Dense)                  (None, 32)           2080        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " char4 (Dense)                  (None, 32)           2080        ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,993,536\n",
            "Trainable params: 278,848\n",
            "Non-trainable params: 14,714,688\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model2.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3815bf66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3815bf66",
        "outputId": "20dc4770-c9d0-446e-d335-b92ec6ad14b4"
      },
      "outputs": [],
      "source": [
        "with open('encoder.bin','rb')as f:\n",
        "    encoder = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a2dfb49f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2dfb49f",
        "outputId": "3c4fb952-9ec6-4d08-f4b0-addaa7e360a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E',\n",
              "       'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',\n",
              "       'U', 'V', 'W', 'X', 'Y', 'Z'], dtype='<U1')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2e5472b9",
      "metadata": {
        "id": "2e5472b9"
      },
      "outputs": [],
      "source": [
        "# def datagenerator(path, batch_size=100):\n",
        "#     pattern= os.path.join(path,'*.png')\n",
        "#     fills= glob(pattern)\n",
        "#     while True:\n",
        "#         offset=0\n",
        "#         while offset<len(fills):\n",
        "#             items = fills[offset:offset+batch_size]\n",
        "#             offset+=batch_size\n",
        "#             x = []\n",
        "#             y1 = []\n",
        "#             y2 = []\n",
        "#             y3 = []\n",
        "#             y4 = []\n",
        "#             for f in items:\n",
        "#                 char = list(os.path.splitext(os.path.basename(f))[0])\n",
        "#                 if len(char)!=4:\n",
        "#                     continue\n",
        "#                 im = cv2.imread(f)\n",
        "#                 im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
        "#                 im = cv2.resize(im,(144,48)).astype(np.float32)\n",
        "#                 im = imagenet_utils.preprocess_input(im)\n",
        "#                 x.append(im)\n",
        "#                 char = [to_categorical(encoder.transform([i]),num_classes=len(encoder.classes_)).reshape(-1) for i in char]\n",
        "#                 y1.append(char[0])\n",
        "#                 y2.append(char[1])\n",
        "#                 y3.append(char[2])\n",
        "#                 y4.append(char[3])\n",
        "#             X = np.array(x,ndmin=4)\n",
        "#             Y1 = np.array(y1)\n",
        "#             Y2 = np.array(y2)\n",
        "#             Y3 = np.array(y3)\n",
        "#             Y4 = np.array(y4)\n",
        "#             yield X,(Y1,Y2,Y3,Y4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3079cee7",
      "metadata": {
        "id": "3079cee7"
      },
      "outputs": [],
      "source": [
        "# data = datagenerator('train')\n",
        "# for x,y in data:\n",
        "#     print(len(x),len(y))\n",
        "#     # print(x.shape,y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "JBBZbVBQZjzm",
      "metadata": {
        "id": "JBBZbVBQZjzm"
      },
      "outputs": [],
      "source": [
        "# # تعریف output_signature برای ۴ خروجی\n",
        "# num_classes = len(encoder.classes_)\n",
        "# output_signature = (\n",
        "#     tf.TensorSpec(shape=(None, 48, 144, 3), dtype=tf.float32),  # ورودی تصویر\n",
        "#     (\n",
        "#         tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),  # Y1\n",
        "#         tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),  # Y2\n",
        "#         tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32),  # Y3\n",
        "#         tf.TensorSpec(shape=(None, num_classes), dtype=tf.float32)   # Y4\n",
        "#     )\n",
        "# )\n",
        "\n",
        "\n",
        "# def create_dataset(path, batch_size=100):\n",
        "#     def gen():\n",
        "#         return datagenerator(path, batch_size)\n",
        "\n",
        "#     dataset = tf.data.Dataset.from_generator(\n",
        "#         gen,\n",
        "#         output_signature=output_signature\n",
        "#     )\n",
        "#     return dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e18786e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e18786e8",
        "outputId": "a4b41b3f-a7cf-490c-fcea-29d233f2b05b"
      },
      "outputs": [],
      "source": [
        "# train_dir = 'train'\n",
        "# val_dir   = 'test'\n",
        "\n",
        "# batch_size = 100\n",
        "# steps_per_epoch  = max(1, len(glob(train_dir+'/*.png')) // batch_size)\n",
        "# val_steps        = max(1, len(glob(val_dir  +'/*.png')) // batch_size)\n",
        "\n",
        "# # h = model2.fit(\n",
        "# #     datagenerator(train_dir, batch_size=batch_size),\n",
        "# #     steps_per_epoch=steps_per_epoch,\n",
        "# #     epochs=40\n",
        "# # )\n",
        "\n",
        "\n",
        "\n",
        "# train_dataset = create_dataset(train_dir, batch_size)\n",
        "# val_dataset = create_dataset(val_dir, batch_size)\n",
        "\n",
        "# h = model2.fit(\n",
        "#     train_dataset,\n",
        "#     steps_per_epoch=steps_per_epoch,\n",
        "#     epochs=50,\n",
        "#     validation_data=val_dataset,\n",
        "#     validation_steps=val_steps\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "05d833d1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "308/308 [==============================] - 42s 99ms/step - loss: 12.8536 - char1_loss: 2.8534 - char2_loss: 3.4254 - char3_loss: 3.3958 - char4_loss: 3.1790 - char1_accuracy: 0.2237 - char2_accuracy: 0.0745 - char3_accuracy: 0.0892 - char4_accuracy: 0.1287\n",
            "Epoch 2/10\n",
            "308/308 [==============================] - 28s 92ms/step - loss: 9.0401 - char1_loss: 1.3360 - char2_loss: 2.8310 - char3_loss: 2.8141 - char4_loss: 2.0591 - char1_accuracy: 0.5866 - char2_accuracy: 0.1999 - char3_accuracy: 0.2080 - char4_accuracy: 0.3956\n",
            "Epoch 3/10\n",
            "308/308 [==============================] - 27s 88ms/step - loss: 7.0026 - char1_loss: 0.8272 - char2_loss: 2.3596 - char3_loss: 2.3382 - char4_loss: 1.4776 - char1_accuracy: 0.7278 - char2_accuracy: 0.2911 - char3_accuracy: 0.3098 - char4_accuracy: 0.5392\n",
            "Epoch 4/10\n",
            "308/308 [==============================] - 28s 91ms/step - loss: 5.9388 - char1_loss: 0.6085 - char2_loss: 2.0739 - char3_loss: 2.0617 - char4_loss: 1.1947 - char1_accuracy: 0.8013 - char2_accuracy: 0.3604 - char3_accuracy: 0.3682 - char4_accuracy: 0.6169\n",
            "Epoch 5/10\n",
            "308/308 [==============================] - 29s 95ms/step - loss: 5.2883 - char1_loss: 0.5074 - char2_loss: 1.8822 - char3_loss: 1.8721 - char4_loss: 1.0266 - char1_accuracy: 0.8307 - char2_accuracy: 0.4079 - char3_accuracy: 0.4180 - char4_accuracy: 0.6642\n",
            "Epoch 6/10\n",
            "308/308 [==============================] - 31s 100ms/step - loss: 4.8412 - char1_loss: 0.4319 - char2_loss: 1.7309 - char3_loss: 1.7490 - char4_loss: 0.9294 - char1_accuracy: 0.8586 - char2_accuracy: 0.4441 - char3_accuracy: 0.4475 - char4_accuracy: 0.6936\n",
            "Epoch 7/10\n",
            "308/308 [==============================] - 29s 94ms/step - loss: 4.5481 - char1_loss: 0.3950 - char2_loss: 1.6348 - char3_loss: 1.6663 - char4_loss: 0.8520 - char1_accuracy: 0.8677 - char2_accuracy: 0.4790 - char3_accuracy: 0.4723 - char4_accuracy: 0.7175\n",
            "Epoch 8/10\n",
            "308/308 [==============================] - 28s 91ms/step - loss: 4.2603 - char1_loss: 0.3430 - char2_loss: 1.5538 - char3_loss: 1.5761 - char4_loss: 0.7874 - char1_accuracy: 0.8863 - char2_accuracy: 0.5026 - char3_accuracy: 0.4995 - char4_accuracy: 0.7374\n",
            "Epoch 9/10\n",
            "308/308 [==============================] - 28s 92ms/step - loss: 4.0463 - char1_loss: 0.3140 - char2_loss: 1.4690 - char3_loss: 1.5180 - char4_loss: 0.7453 - char1_accuracy: 0.8990 - char2_accuracy: 0.5276 - char3_accuracy: 0.5187 - char4_accuracy: 0.7538\n",
            "Epoch 10/10\n",
            "308/308 [==============================] - 29s 93ms/step - loss: 3.8575 - char1_loss: 0.2925 - char2_loss: 1.4077 - char3_loss: 1.4523 - char4_loss: 0.7050 - char1_accuracy: 0.9033 - char2_accuracy: 0.5401 - char3_accuracy: 0.5355 - char4_accuracy: 0.7619\n"
          ]
        }
      ],
      "source": [
        "def load_data(p):\n",
        "    pattern = os.path.join(p,'*.png')\n",
        "    files = glob(pattern)\n",
        "    x = []\n",
        "    y1 = []\n",
        "    y2 = []\n",
        "    y3 = []\n",
        "    y4 = []\n",
        "    for f in files:\n",
        "        char = list(os.path.splitext(os.path.basename(f))[0])\n",
        "        if len(char)!=4:\n",
        "            continue\n",
        "        im = cv2.imread(f)\n",
        "        # im = img_to_array(im)\n",
        "        im = cv2.resize(im,(144,48))\n",
        "        im = imagenet_utils.preprocess_input(im)\n",
        "        \n",
        "        x.append(im)\n",
        "        char = [to_categorical(encoder.transform([i])[0], num_classes=len(encoder.classes_)) for i in char]\n",
        "\n",
        "        y1.append(char[0])\n",
        "        y2.append(char[1])\n",
        "        y3.append(char[2])\n",
        "        y4.append(char[3])\n",
        "    X = np.array(x,ndmin=4)\n",
        "    Y1 = np.array(y1)\n",
        "    Y2 = np.array(y2)\n",
        "    Y3 = np.array(y3)\n",
        "    Y4 = np.array(y4)\n",
        "    return X,Y1,Y2,Y3,Y4\n",
        "\n",
        "x_train,Y1,Y2,Y3,Y4 = load_data('../2_1_Convolutional/train/')\n",
        "h = model2.fit(x_train, {\"out1\": Y1, \"out2\": Y2, \"out3\": Y3, \"out4\": Y4}, epochs=20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7288eaaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "7288eaaa",
        "outputId": "6f8e3bc2-40e3-42f2-811d-332ddf17bfa0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x214e6a20790>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "f = ('../2_1_Convolutional/test/F9AX.png')\n",
        "im = cv2.imread(f)\n",
        "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
        "im = cv2.resize(im,(144,48))\n",
        "im = np.array(im)\n",
        "f = imagenet_utils.preprocess_input(im)\n",
        "# f = cv2.resize(f,(144,48))\n",
        "# f.shape\n",
        "plt.imshow(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "db598832",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db598832",
        "outputId": "f22239ac-7f15-4ff8-d785-4d546cca1cf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 811ms/step\n"
          ]
        }
      ],
      "source": [
        "p = model2.predict(f.reshape(1,48,144,3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9527eadb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9527eadb",
        "outputId": "91df26d8-9236-4990-c019-d2361f644a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['F']\n",
            "['6']\n",
            "['A']\n",
            "['X']\n"
          ]
        }
      ],
      "source": [
        "for i in p:\n",
        "    # print(np.argmax(i))\n",
        "    print(encoder.inverse_transform([np.argmax(i)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AD_Fm17fd9gW",
      "metadata": {
        "id": "AD_Fm17fd9gW"
      },
      "outputs": [],
      "source": [
        "model2.save('model2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5NTthbvJfIJc",
      "metadata": {
        "id": "5NTthbvJfIJc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-gpu-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
