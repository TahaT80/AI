{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c698c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377276d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False,input_shape=(48,144,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2b738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 144, 3)]      0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 144, 64)       1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 144, 64)       36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 72, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 72, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 72, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 36, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 36, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 36, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 36, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 18, 256)        0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 18, 512)        1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 18, 512)        2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 18, 512)        2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72fa7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in model.layers:\n",
    "    l.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8a5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Flatten()(model.output)\n",
    "a = Dense(64,activation='relu')(a)\n",
    "a = Dense(32,activation='softmax')(a)\n",
    "model2 = Model(model.input,a)\n",
    "model2.compile('adam','categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dfffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 144, 3)]      0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 144, 64)       1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 144, 64)       36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 72, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 72, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 72, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 36, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 36, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 36, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 36, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 18, 256)        0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 18, 512)        1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 18, 512)        2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 18, 512)        2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                131136    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,847,904\n",
      "Trainable params: 133,216\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3815bf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('encoder.bin','rb')as f:\n",
    "    encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2dfb49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E',\n",
       "       'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',\n",
       "       'U', 'V', 'W', 'X', 'Y', 'Z'], dtype='<U1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5472b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenerator(path, batch_size=100,c=0):\n",
    "    pattern= os.path.join(path,'*.png')\n",
    "    fills= glob(pattern)\n",
    "    offset=0\n",
    "    while True:\n",
    "        offset = 0\n",
    "        while offset<len(fills):\n",
    "            items = fills[offset:offset+batch_size]\n",
    "            offset+=batch_size\n",
    "            x = []\n",
    "            y = []\n",
    "            for f in items:\n",
    "                char = list(os.path.splitext(os.path.basename(f))[0])[c]\n",
    "                im = cv2.imread(f)\n",
    "                # im = img_to_array(im)\n",
    "                im = cv2.resize(im,(144,48))\n",
    "                im = imagenet_utils.preprocess_input(im)\n",
    "                \n",
    "                x.append(im)\n",
    "                y.append(to_categorical(encoder.transform([char]),num_classes=len(encoder.classes_)).reshape(-1))\n",
    "            X = np.array(x,ndmin=4)\n",
    "            Y = np.array(y,ndmin=2)\n",
    "            yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3079cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "(100, 48, 144, 3) (100, 32)\n"
     ]
    }
   ],
   "source": [
    "data = datagenerator('../2_1_Convolutional/train/')\n",
    "x, y = next(data)\n",
    "print(len(x), len(y))\n",
    "print(x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18786e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 [==============================] - 37s 239ms/step - loss: 4.6725 - accuracy: 0.0085\n",
      "Epoch 2/10\n",
      "98/98 [==============================] - 28s 239ms/step - loss: 3.4029 - accuracy: 0.0317\n",
      "Epoch 3/10\n",
      "98/98 [==============================] - 23s 238ms/step - loss: 3.4023 - accuracy: 0.0763\n",
      "Epoch 4/10\n",
      "98/98 [==============================] - 23s 238ms/step - loss: 3.1282 - accuracy: 0.0837\n",
      "Epoch 5/10\n",
      "98/98 [==============================] - 23s 239ms/step - loss: 3.0521 - accuracy: 0.1177\n",
      "Epoch 6/10\n",
      "98/98 [==============================] - 24s 242ms/step - loss: 2.9222 - accuracy: 0.1850\n",
      "Epoch 7/10\n",
      "98/98 [==============================] - 32s 323ms/step - loss: 2.7956 - accuracy: 0.1914\n",
      "Epoch 8/10\n",
      "98/98 [==============================] - 23s 239ms/step - loss: 2.6573 - accuracy: 0.2256\n",
      "Epoch 9/10\n",
      "98/98 [==============================] - 24s 246ms/step - loss: 2.4488 - accuracy: 0.2601\n",
      "Epoch 10/10\n",
      "98/98 [==============================] - 23s 239ms/step - loss: 2.3664 - accuracy: 0.2931\n"
     ]
    }
   ],
   "source": [
    "train_path = '../2_1_Convolutional/train/'\n",
    "train_files = glob(os.path.join(train_path, '*.png'))\n",
    "batch_size = 100\n",
    "\n",
    "steps_per_epoch = len(train_files) // batch_size\n",
    "h = model2.fit(datagenerator('../2_1_Convolutional/train/'),epochs=20  ,  steps_per_epoch=steps_per_epoch,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483eeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(p):\n",
    "#     pattern = os.path.join(p,'*.png')\n",
    "#     files = glob(pattern)\n",
    "#     x = []\n",
    "#     y = []\n",
    "#     for f in files:\n",
    "#         char = list(os.path.splitext(os.path.basename(f))[0])[0]\n",
    "#         im = cv2.imread(f)\n",
    "#         # im = img_to_array(im)\n",
    "#         im = cv2.resize(im,(144,48))\n",
    "#         im = imagenet_utils.preprocess_input(im)\n",
    "        \n",
    "#         x.append(im)\n",
    "#         y.append(to_categorical(encoder.transform([char]),num_classes=len(encoder.classes_)).reshape(-1))\n",
    "#     X = np.array(x,ndmin=4)\n",
    "#     Y = np.array(y,ndmin=2)\n",
    "#     return X,Y\n",
    "\n",
    "# x_train,y_train = load_data('../2_1_Convolutional/train/')\n",
    "# h = model2.fit(x_train,y_train,epochs=10 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7288eaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22e184a8a00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = ('../2_1_Convolutional/test/H4DW.png')\n",
    "im = cv2.imread(f)\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "im = cv2.resize(im,(144,48))\n",
    "im = np.array(im)\n",
    "im = imagenet_utils.preprocess_input(im)\n",
    "plt.imshow(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db598832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 171ms/step\n"
     ]
    }
   ],
   "source": [
    "p = model2.predict(im.reshape(1,48,144,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d740a524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U'], dtype='<U1')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform((p[0].argmax(),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dde06d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
